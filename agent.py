import requests
import json

# Load configuration values from external JSON file (for API key safety)
with open("api-keys.json", "r") as f:
    config = json.load(f)

# Extract API credentials and project metadata from config
api_key = config["openrouter_api_key"]
referer = config.get("referer", "http://localhost")
title = config.get("project_title", "Agent Project")

def send_prompt(prompt: str) -> str:
    """
    Sends a user prompt to the OpenRouter API using the specified LLM model,
    and returns the generated response from the model.
    
    Args:
        prompt (str): The user's request or instruction for the agent.
    
    Returns:
        str: The assistant's reply generated by the language model.
    """

    # Define request headers with API key and project context
    headers = {
        "Authorization": f"Bearer {api_key}",
        "HTTP-Referer": referer,
        "X-Title": title
    }

    # Define the payload (prompt and model selection)
    data = {
        "model": "mistralai/mistral-small-3.2-24b-instruct:free",
        "messages": [
            {"role": "system", "content": "You are an assistant that writes email drafts."},
            {"role": "user", "content": prompt}
        ]
    }

    # Make a POST request to the OpenRouter Chat Completions API
    response = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers=headers,
        json=data
    )

    # Extract and return the generated message from the response
    message = response.json()["choices"][0]["message"]["content"]
    return message
